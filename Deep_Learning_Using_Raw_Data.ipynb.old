{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz14ahc4DxMC"
      },
      "source": [
        "## Unzip The Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TnEz9mvDxMD",
        "outputId": "fee67cb3-3073-4464-a585-bfb620356152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.11.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /home/erklarungsnot/miniconda3/lib/python3.10/site-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: keras-tuner, tflite-model-maker\n"
          ]
        }
      ],
      "source": [
        "!./unzip.sh UCI_HAR_Dataset.zip 2>&1 > /dev/null\n",
        "%pip install -q --no-dependencies tflite-model-maker\n",
        "%pip install -q tensorflow==2.11.0\n",
        "!pip show tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35GVajx3DxME",
        "outputId": "b21a7522-f850-478e-c7de-d58fc6762c38"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-08 22:11:19.859078: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-08 22:11:20.115902: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-05-08 22:11:20.115926: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-05-08 22:11:21.148041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-05-08 22:11:21.148091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-05-08 22:11:21.148097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "# tf.enable_control_flow_v2() # only for tf 1.0\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import LSTM, BatchNormalization, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import L1L2\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\", message=\"calling BaseResourceVariable.__init__.*constraint is deprecated\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_EtCSRNDxMF"
      },
      "source": [
        "## Building The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIcaFPXWDxMF"
      },
      "outputs": [],
      "source": [
        "def get_one_hot(targets, nb_classes):\n",
        "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
        "    return res.reshape(list(targets.shape) + [nb_classes])\n",
        "\n",
        "\n",
        "def load_y(subset):\n",
        "    # Get the path\n",
        "    path = f\"UCI_HAR_Dataset/UCI_HAR_Dataset/{subset}/y_{subset}.txt\"\n",
        "\n",
        "    # Read the file\n",
        "    y = np.loadtxt(path, delimiter=\",\", dtype=int)\n",
        "\n",
        "    # # One-hot encode labels\n",
        "    one_hot_labels = get_one_hot(y - 1, len(np.unique(y)))\n",
        "    if subset == \"train\":\n",
        "        assert one_hot_labels.shape == (\n",
        "            7352,\n",
        "            6,\n",
        "        ), f\"Wrong dimensions: {one_hot_labels.shape} should be (7352, 6)\"\n",
        "    if subset == \"test\":\n",
        "        assert one_hot_labels.shape == (\n",
        "            2947,\n",
        "            6,\n",
        "        ), f\"Wrong dimensions: {one_hot_labels.shape} should be (2947, 6)\"\n",
        "    assert (\n",
        "        y[0] - 1 == np.where(one_hot_labels[0] == np.max(one_hot_labels[0]))[0][0]\n",
        "    ), f\"Value mismatch {np.max(one_hot_labels[0])[0][0]} vs {y[13] - 1}\"\n",
        "    return one_hot_labels.astype('float32')\n",
        "\n",
        "\n",
        "def build_data(subset):\n",
        "    if subset not in [\"train\", \"val\", \"test\"]:\n",
        "        raise Exception(f\"Invalid subset: {subset}\")\n",
        "\n",
        "    folder_path = f\"UCI_HAR_Dataset/UCI_HAR_Dataset/{subset}/Inertial Signals/\"\n",
        "\n",
        "    # Get all signal files in folder\n",
        "    signal_files = glob.glob(os.path.join(folder_path, \"*.txt\"))\n",
        "    # print(signal_files)\n",
        "\n",
        "    assert len(signal_files) == 9, f\"No signal files found in {folder_path}\"\n",
        "    np.loadtxt(signal_files[0]).shape\n",
        "    # print(f\"{signal_shape}\")\n",
        "\n",
        "    # Determine signal order based on file names\n",
        "    signal_order = [\n",
        "        \"body_acc_x_\",\n",
        "        \"body_acc_y_\",\n",
        "        \"body_acc_z_\",\n",
        "        \"body_gyro_x_\",\n",
        "        \"body_gyro_y_\",\n",
        "        \"body_gyro_z_\",\n",
        "        \"total_acc_x_\",\n",
        "        \"total_acc_y_\",\n",
        "        \"total_acc_z_\",\n",
        "    ]\n",
        "\n",
        "    # file_prefix = \"UCI_HAR_Dataset/UCI_HAR_Dataset/train/Inertial Signals/\"\n",
        "    # file_suffix = \".txt\"\n",
        "    signal_files = [\n",
        "        f\"UCI_HAR_Dataset/UCI_HAR_Dataset/{subset}/Inertial Signals/{x}{subset}.txt\"\n",
        "        for x in signal_order\n",
        "    ]\n",
        "\n",
        "    # Load signal data from each file and append to signals_data list\n",
        "    signals_data = [np.loadtxt(x) for x in signal_files]\n",
        "\n",
        "    # Transpose signal data array so that shape is (number of samples, number of timesteps, number of signals)\n",
        "    signals_data = np.transpose(signals_data, (1, 2, 0))\n",
        "\n",
        "    # Verify final shape of combined data\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    if subset == \"train\":\n",
        "        assert signals_data.shape == (7352, 128, len(signal_files))\n",
        "    else:\n",
        "        assert signals_data.shape == (2947, 128, len(signal_files))\n",
        "    return signals_data.astype('float32')\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    return build_data(\"train\"), load_y(\"train\"), build_data(\"test\"), load_y(\"test\")\n",
        "\n",
        "\n",
        "# Loading the train and test data\n",
        "X_train, y_train, X_test, y_test = load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie4hgy4cDxMG"
      },
      "outputs": [],
      "source": [
        "# Data verification\n",
        "\n",
        "print(f\"X_train data type: {X_train.dtype}\\ny_test data type:{y_test.dtype}\")\n",
        "\n",
        "first_sample = X_train[0]\n",
        "first_timestep = first_sample[0]\n",
        "assert len(first_sample) == 128\n",
        "assert X_train.shape == (7352, 128, 9), print(\n",
        "    \"Expected shape: (7352, 128, 9) get\", X_train.shape\n",
        ")\n",
        "assert X_test.shape == (2947, 128, 9), print(\n",
        "    \"Expected: (2947, 128, 9) get\", X_test.shape\n",
        ")\n",
        "assert y_train.shape == (7352, 6), print(\"Expected: (7352, 6) get\", y_train.shape)\n",
        "assert y_test.shape == (2947, 6), print(\"Expected: (2947, 6) get\", y_test.shape)\n",
        "assert len(X_train[0][0]) == 9, print(\"Signals numbers not match\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK9Sn_KuDxMH"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Create the \"assets\" folder if it does not exist\n",
        "if not os.path.exists(\"assets\"):\n",
        "    os.mkdir(\"assets\")\n",
        "\n",
        "# Create the \"assets/data\" folder if it does not exist\n",
        "data_folder = os.path.join(\"assets\", \"data\")\n",
        "if not os.path.exists(data_folder):\n",
        "    os.mkdir(data_folder)\n",
        "\n",
        "\n",
        "def save_data_to_pickle_shards(data, data_name, data_folder):\n",
        "    # Check if the data already exists\n",
        "    filename = os.path.join(data_folder, f\"{data_name}_0.pickle\")\n",
        "    if os.path.exists(filename):\n",
        "        print(f\"{data_name} already exists in {data_folder}. Skipping data saving.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(os.path.join(data_folder)):\n",
        "        os.makedirs(os.path.join(data_folder))\n",
        "\n",
        "    # Serialize your data\n",
        "    serialized_data = pickle.dumps(data)\n",
        "\n",
        "    # Split the serialized data into smaller chunks\n",
        "    chunk_size = 50 * 1024 * 1024  # 50 megabytes\n",
        "    chunks = [\n",
        "        serialized_data[i : i + chunk_size]\n",
        "        for i in range(0, len(serialized_data), chunk_size)\n",
        "    ]\n",
        "\n",
        "    # Save each chunk to a file in the \"asset/data\" folder\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        filename = os.path.join(data_folder, f\"{data_name}_{i}.pickle\")\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(chunk)\n",
        "\n",
        "def load_data_from_pickle_shards(data_name, data_folder):\n",
        "    # Find all pickle files that match the data name\n",
        "    files = sorted(\n",
        "        [\n",
        "            os.path.join(data_folder, f)\n",
        "            for f in os.listdir(data_folder)\n",
        "            if f.startswith(data_name)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Load the data from each file\n",
        "    data = b\"\"\n",
        "    for filename in files:\n",
        "        with open(filename, \"rb\") as f:\n",
        "            data += f.read()\n",
        "\n",
        "    # Deserialize the data\n",
        "    return pickle.loads(data)\n",
        "\n",
        "save_data_to_pickle_shards(X_train, \"X_train\", data_folder)\n",
        "save_data_to_pickle_shards(y_train, \"y_train\", data_folder)\n",
        "save_data_to_pickle_shards(X_test, \"X_test\", data_folder)\n",
        "save_data_to_pickle_shards(y_test, \"y_test\", data_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggNf5frVDxMH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "# Load the data from the pickle shards\n",
        "loaded_X_train = load_data_from_pickle_shards(\"X_train\", data_folder)\n",
        "loaded_y_train = load_data_from_pickle_shards(\"y_train\", data_folder)\n",
        "loaded_X_test = load_data_from_pickle_shards(\"X_test\", data_folder)\n",
        "loaded_y_test = load_data_from_pickle_shards(\"y_test\", data_folder)\n",
        "\n",
        "# Check if the loaded data matches the original data\n",
        "assert loaded_X_train.shape == X_train.shape\n",
        "assert loaded_y_train.shape == y_train.shape\n",
        "assert loaded_X_test.shape == X_test.shape\n",
        "assert loaded_y_test.shape == y_test.shape\n",
        "\n",
        "assert (loaded_X_train == X_train).all()\n",
        "assert (loaded_y_train == y_train).all()\n",
        "assert (loaded_X_test == X_test).all()\n",
        "assert (loaded_y_test == y_test).all()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify Rebuild Database"
      ],
      "metadata": {
        "id": "SnJkzNhhE-LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "success_thresh = 10\n",
        "passed = 0\n",
        "\n",
        "def compare_array_halves(array1, array2):\n",
        "    n = len(array1) // 2\n",
        "    return np.array_equal(array1[:n], array2[n:])\n",
        "\n",
        "\n",
        "for i in range(len(loaded_X_train)):\n",
        "    for j in range(len(loaded_X_train)):\n",
        "        if i == j:\n",
        "            continue\n",
        "        result = compare_array_halves(loaded_X_train[i], loaded_X_train[j])\n",
        "        if result:\n",
        "            passed += 1\n",
        "            print(\n",
        "                f\"The first half of array{i} is equal to the second half of array{j}.\"\n",
        "            )\n",
        "            break\n",
        "    if passed == success_thresh:\n",
        "        print(f\"Success threshhold passed, stopping check\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "Fhtty8LHFDRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnrnqIjuDxMI"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ufG7a4gDxMI",
        "outputId": "dad957eb-d588-47d2-baf4-d1b44857b11e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               147584    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 156,230\n",
            "Trainable params: 156,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-08 22:11:24.323399: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-05-08 22:11:24.323467: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "2023-05-08 22:11:24.323504: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "2023-05-08 22:11:24.323539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
            "2023-05-08 22:11:24.452106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
            "2023-05-08 22:11:24.453406: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# function to count the number of classes\n",
        "def count_classes(y):\n",
        "    return len(set([tuple(category) for category in y]))\n",
        "\n",
        "timesteps = len(X_train[0])\n",
        "input_dim = len(X_train[0][0])\n",
        "n_classes = count_classes(y_train)\n",
        "\n",
        "# Initializing parameters\n",
        "n_epochs = 30\n",
        "n_batch = 16\n",
        "\n",
        "# Model execution\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(timesteps, input_dim)),\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(units=64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(units=n_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mj-3ieZJDxMI",
        "outputId": "8d7f21ae-7e7d-4844-fd3e-75d88b13b3ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 1.0132 - accuracy: 0.5993 - val_loss: 0.6308 - val_accuracy: 0.8008\n",
            "Epoch 2/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.6115 - accuracy: 0.7775 - val_loss: 0.4714 - val_accuracy: 0.8395\n",
            "Epoch 3/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.4585 - accuracy: 0.8366 - val_loss: 0.4139 - val_accuracy: 0.8782\n",
            "Epoch 4/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.3842 - accuracy: 0.8618 - val_loss: 0.4139 - val_accuracy: 0.8846\n",
            "Epoch 5/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8740 - val_loss: 0.5039 - val_accuracy: 0.8548\n",
            "Epoch 6/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.3120 - accuracy: 0.8864 - val_loss: 0.4449 - val_accuracy: 0.8870\n",
            "Epoch 7/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.3005 - accuracy: 0.8898 - val_loss: 0.5057 - val_accuracy: 0.8707\n",
            "Epoch 8/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.2798 - accuracy: 0.8946 - val_loss: 0.4699 - val_accuracy: 0.8748\n",
            "Epoch 9/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.2650 - accuracy: 0.8962 - val_loss: 0.4673 - val_accuracy: 0.8860\n",
            "Epoch 10/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.2588 - accuracy: 0.9094 - val_loss: 0.5853 - val_accuracy: 0.8758\n",
            "Epoch 11/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.9072 - val_loss: 0.5131 - val_accuracy: 0.8799\n",
            "Epoch 12/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.2412 - accuracy: 0.9072 - val_loss: 0.5484 - val_accuracy: 0.8843\n",
            "Epoch 13/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.2429 - accuracy: 0.9093 - val_loss: 0.6584 - val_accuracy: 0.8571\n",
            "Epoch 14/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.2303 - accuracy: 0.9121 - val_loss: 0.4942 - val_accuracy: 0.8904\n",
            "Epoch 15/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9159 - val_loss: 0.6254 - val_accuracy: 0.8765\n",
            "Epoch 16/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.2271 - accuracy: 0.9149 - val_loss: 0.6465 - val_accuracy: 0.8687\n",
            "Epoch 17/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.2185 - accuracy: 0.9177 - val_loss: 0.6174 - val_accuracy: 0.8721\n",
            "Epoch 18/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.2175 - accuracy: 0.9159 - val_loss: 0.6923 - val_accuracy: 0.8609\n",
            "Epoch 19/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.2207 - accuracy: 0.9168 - val_loss: 0.5606 - val_accuracy: 0.8897\n",
            "Epoch 20/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.2167 - accuracy: 0.9174 - val_loss: 0.5865 - val_accuracy: 0.8799\n",
            "Epoch 21/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.1962 - accuracy: 0.9211 - val_loss: 0.6244 - val_accuracy: 0.8884\n",
            "Epoch 22/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.1936 - accuracy: 0.9282 - val_loss: 0.6381 - val_accuracy: 0.8884\n",
            "Epoch 23/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.2051 - accuracy: 0.9233 - val_loss: 0.6085 - val_accuracy: 0.8846\n",
            "Epoch 24/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.2006 - accuracy: 0.9271 - val_loss: 0.6566 - val_accuracy: 0.8724\n",
            "Epoch 25/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.9249 - val_loss: 0.7279 - val_accuracy: 0.8707\n",
            "Epoch 26/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.1994 - accuracy: 0.9287 - val_loss: 0.6539 - val_accuracy: 0.8890\n",
            "Epoch 27/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.1841 - accuracy: 0.9251 - val_loss: 0.6467 - val_accuracy: 0.8768\n",
            "Epoch 28/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.1967 - accuracy: 0.9249 - val_loss: 0.6284 - val_accuracy: 0.8941\n",
            "Epoch 29/30\n",
            "460/460 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.9304 - val_loss: 0.5878 - val_accuracy: 0.8931\n",
            "Epoch 30/30\n",
            "460/460 [==============================] - 1s 1ms/step - loss: 0.1812 - accuracy: 0.9294 - val_loss: 0.6166 - val_accuracy: 0.8901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: simple_ffnn_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: simple_ffnn_model/assets\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "# Training the model\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=n_batch,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=n_epochs,\n",
        ")\n",
        "# model.save(\"assets/model-backup.h5\")\n",
        "model.save(\"assets/simple_ffnn_model\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrU25GEODxMJ"
      },
      "source": [
        "## Rebuilding Model From Backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmqBWCM8DxMJ"
      },
      "outputs": [],
      "source": [
        "# It can be used to reconstruct the model identically.\n",
        "reconstructed_model = keras.models.load_model(\"assets/model-backup.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B2pNSAwDxMJ"
      },
      "source": [
        "### Checking The Rebuilt Model From Backup File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vzrj802cDxMJ"
      },
      "outputs": [],
      "source": [
        "test_input = X_test[0].reshape((1, 128, 9))\n",
        "\n",
        "# Let's check:\n",
        "np.testing.assert_allclose(\n",
        "    model.predict(test_input), reconstructed_model.predict(test_input)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Uiuj_tjDxMJ",
        "outputId": "7bbc7cb0-65aa-4b47-c40b-5eb715289b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ],
      "source": [
        "assert np.array(model.predict(test_input)).argmax() + 1 == np.array(y_test[0]).argmax() + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ0IvSWxDxMK"
      },
      "outputs": [],
      "source": [
        "# It can be used to reconstruct the model identically.\n",
        "reconstructed_model = keras.models.load_model(\"assets/model-backup.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39ycGndgDxMK"
      },
      "source": [
        "## Converting Keras Model to TFLite Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRVpnK3zDxMK"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# model_path = 'assets/model-backup.h5'\n",
        "# model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# model_path_alt = 'assets/saved/'\n",
        "# tf.saved_model.save(model, model_path_alt)\n",
        "\n",
        "# tf.keras.backend.clear_session()\n",
        "\n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model(model_path_alt)\n",
        "# converter.target_spec.supported_ops = [\n",
        "#     tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "#     tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "# ]\n",
        "\n",
        "# tflite_model = converter.convert()\n",
        "\n",
        "# with open('assets/ff-model.tflite', 'wb') as f:\n",
        "#     f.write(tflite_model)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"simple_ffnn_model\")\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"simple_ffnn_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "4d37fff4659cf8a883ce3d6c1246076e30e33dc297d4df960d23d9670e4eb60f"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}